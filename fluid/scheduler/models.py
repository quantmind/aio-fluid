from __future__ import annotations

import asyncio
import enum
import inspect
import logging
import os
import sys
import json
from dataclasses import dataclass
from datetime import datetime
from typing import TYPE_CHECKING, Any, Callable, Coroutine, NamedTuple, overload

from pydantic import BaseModel, Field, field_serializer
from redis.asyncio.lock import Lock

from fluid import settings
from fluid.utils import kernel
from fluid.utils.text import trim_docstring

from .crontab import Scheduler

if TYPE_CHECKING:
    from .consumer import TaskManager


TaskExecutor = Callable[["TaskRun"], Coroutine[Any, Any, Any]]
RandomizeType = Callable[[], float | int]


class TaskPriority(enum.StrEnum):
    high = enum.auto()
    medium = enum.auto()
    low = enum.auto()


class TaskState(enum.StrEnum):
    init = enum.auto()
    queued = enum.auto()
    running = enum.auto()
    success = enum.auto()
    failure = enum.auto()
    aborted = enum.auto()
    rate_limited = enum.auto()

    @property
    def is_failure(self) -> bool:
        return self is TaskState.failure


FINISHED_STATES = frozenset(
    (TaskState.success, TaskState.failure, TaskState.aborted, TaskState.rate_limited)
)


class TaskManagerConfig(BaseModel):
    schedule_tasks: bool = True
    consume_tasks: bool = True
    max_concurrent_tasks: int = settings.MAX_CONCURRENT_TASKS
    """number of coroutine workers"""
    sleep: float = 0.1
    """amount to sleep after completion of a task"""
    broker_url: str = ""


class TaskInfo(BaseModel):
    name: str = Field(description="Task name")
    description: str = Field(description="Task description")
    priority: TaskPriority = Field(description="Task priority")
    schedule: str | None = Field(default=None, description="Task schedule")
    enabled: bool = Field(default=True, description="Task enabled")
    last_run_end: int | None = Field(
        default=None, description="Task last run end as milliseconds since epoch"
    )
    last_run_duration: int | None = Field(
        default=None, description="Task last run duration in milliseconds"
    )
    last_run_state: str | None = Field(
        default=None, description="State of last task run"
    )


class QueuedTask(BaseModel):
    """A task to be queued"""

    run_id: str = Field(description="Task run id")
    task: str = Field(description="Task name")
    params: dict[str, Any] = Field(description="Task parameters")
    priority: TaskPriority | None = Field(default=None, description="Task priority")


class Task(NamedTuple):
    """A Task execute any time it is invoked"""

    name: str
    executor: TaskExecutor
    logger: logging.Logger
    module: str = ""
    description: str = ""
    schedule: Scheduler | None = None
    randomize: RandomizeType | None = None
    params_model: type[BaseModel] | None = None
    max_concurrency: int = 0
    """how many tasks can run in each consumer concurrently - 0 means no limit"""
    priority: TaskPriority = TaskPriority.medium

    def params_dump_json(self, params: dict[str, Any]) -> str:
        if params_model := self.params_model:
            return params_model(**params).model_dump_json()
        return json.dumps(params)


class TaskRun(BaseModel, arbitrary_types_allowed=True):
    """A TaskRun contains all the data generated by a Task run"""

    id: str
    queued: datetime
    task: Task
    priority: TaskPriority
    params: dict[str, Any]
    state: TaskState
    task_manager: TaskManager = Field(exclude=True, repr=False)
    start: datetime | None = None
    end: datetime | None = None
    waiter: asyncio.Future[Any] = Field(
        default_factory=asyncio.Future, exclude=True, repr=False
    )

    def wrapper(self) -> TaskRunWrapper:
        return TaskRunWrapper(self)

    @field_serializer("task")
    def serialize_task(self, task: Task, _info: Any) -> str:
        return task.name

    @property
    def logger(self) -> logging.Logger:
        return self.task.logger

    @property
    def in_queue(self) -> int:
        return self.start.diff(self.queued)

    @property
    def duration(self) -> int:
        return self.end.diff(self.start)

    @property
    def total(self) -> int:
        return self.end.diff(self.queued)

    @property
    def name(self) -> str:
        return self.task.name

    @property
    def name_id(self) -> str:
        return f"{self.task.name}.{self.id}"

    @property
    def exception(self) -> BaseException | None:
        return self.waiter.exception() if self.waiter.done() else None

    @property
    def result(self) -> Any:
        return (
            self.waiter.result() if self.waiter.done() and not self.exception else None
        )

    @property
    def in_finish_state(self) -> bool:
        return TaskState[self.state] in FINISHED_STATES

    @property
    def is_failure(self) -> bool:
        return self.state.is_failure

    def set_state(self, state: TaskState) -> None:
        self.state = state

    def lock(self, timeout: float | None) -> Lock:
        return self.task_manager.broker.lock(self.name, timeout=timeout)


@dataclass
class TaskRunWrapper:
    task_run: TaskRun

    async def __call__(self) -> None:
        try:
            await self.task_run.task.executor(self.task_run)
        except Exception as exc:
            self.task_run.waiter.set_exception(exc)
        else:
            self.task_run.waiter.set_result(None)


class TaskDecoratorError(RuntimeError):
    pass


class TaskRunError(RuntimeError):
    pass


@overload
def task(executor: TaskExecutor) -> Task: ...


@overload
def task(
    *,
    name: str | None = None,
    schedule: Scheduler | None = None,
    description: str | None = None,
    randomize: RandomizeType | None = None,
    max_concurrency: int = 1,
    priority: TaskPriority = TaskPriority.medium,
    params_model: BaseModel | None = None,
    cpu_bound: bool = False,
) -> TaskConstructor: ...


# implementation of the task decorator
def task(executor: TaskExecutor | None = None, **kwargs: Any) -> Task | TaskConstructor:

    if kwargs and executor:
        raise TaskDecoratorError("cannot use positional parameters")
    elif kwargs:
        return TaskConstructor(**kwargs)
    elif not executor:
        raise TaskDecoratorError("this is a decorator cannot be invoked in this way")
    else:
        return TaskConstructor()(executor)


class TaskConstructor:
    def __init__(self, *, cpu_bound: bool = False, **kwargs: Any) -> None:
        self.cpu_bound = cpu_bound
        self.kwargs = kwargs

    def __call__(self, executor: TaskExecutor) -> Task:
        if self.cpu_bound:
            return self.cpu_bound_task(executor)
        else:
            return self.create_task(executor)

    def create_task(self, executor: TaskExecutor, defaults: dict | None = None) -> Task:
        kwargs: dict[str, Any] = self.kwargs_defaults(executor)
        if defaults:
            kwargs.update(defaults)
        kwargs.update(self.kwargs)
        name = kwargs["name"]
        kwargs.update(
            executor=executor,
            logger=settings.get_logger(f"task.{name}", prefix=True),
        )
        return Task(**kwargs)

    def cpu_bound_task(self, executor: TaskExecutor) -> Task:
        if is_in_subprocess():
            return self.create_task(executor)
        else:
            return self.create_task(run_in_subprocess, self.kwargs_defaults(executor))

    def kwargs_defaults(self, executor: TaskExecutor) -> dict[str, Any]:
        return {
            "name": get_name(executor),
            "module": inspect.getmodule(executor).__name__,
            "description": trim_docstring(inspect.getdoc(executor) or ""),
            "executor": executor,
        }


def get_name(o: Any) -> str:
    if hasattr(o, "__name__"):
        return str(o.__name__)
    elif hasattr(o, "__class__"):
        return str(o.__class__.__name__)
    else:
        return str(o)


def is_in_subprocess() -> bool:
    return os.getenv("TASK_MANAGER_SPAWN") == "true"


class RemoteLog:
    def __init__(self, out: Any) -> None:
        self.out = out

    def __call__(self, data: bytes) -> None:
        self.out.write(data.decode("utf-8"))


async def run_in_subprocess(ctx: TaskRun) -> None:
    env = dict(os.environ)
    env["TASK_MANAGER_SPAWN"] = "true"
    result = await kernel.run_python(
        "-W",
        "ignore",
        "-m",
        "fluid.scheduler.cpubound",
        ctx.name,
        ctx.task.module,
        ctx.id,
        ctx.task.params_dump_json(ctx.params),
        result_callback=RemoteLog(sys.stdout),
        error_callback=RemoteLog(sys.stderr),
        env=env,
        stream_output=True,
        stream_error=True,
    )
    if result:
        ctx.set_state(TaskState.failure)
